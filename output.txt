Mounted at /content/gdrive
Found 28736 images belonging to 7 classes.
Found 3589 images belonging to 7 classes.
Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_1 (Conv2D)            (None, 48, 48, 32)        320       
_________________________________________________________________
activation_1 (Activation)    (None, 48, 48, 32)        0         
_________________________________________________________________
batch_normalization_1 (Batch (None, 48, 48, 32)        128       
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 48, 48, 32)        9248      
_________________________________________________________________
activation_2 (Activation)    (None, 48, 48, 32)        0         
_________________________________________________________________
batch_normalization_2 (Batch (None, 48, 48, 32)        128       
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 24, 24, 32)        0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 24, 24, 32)        0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 24, 24, 64)        18496     
_________________________________________________________________
activation_3 (Activation)    (None, 24, 24, 64)        0         
_________________________________________________________________
batch_normalization_3 (Batch (None, 24, 24, 64)        256       
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 24, 24, 64)        36928     
_________________________________________________________________
activation_4 (Activation)    (None, 24, 24, 64)        0         
_________________________________________________________________
batch_normalization_4 (Batch (None, 24, 24, 64)        256       
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 12, 12, 64)        0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 12, 12, 64)        0         
_________________________________________________________________
conv2d_5 (Conv2D)            (None, 12, 12, 128)       73856     
_________________________________________________________________
activation_5 (Activation)    (None, 12, 12, 128)       0         
_________________________________________________________________
batch_normalization_5 (Batch (None, 12, 12, 128)       512       
_________________________________________________________________
conv2d_6 (Conv2D)            (None, 12, 12, 128)       147584    
_________________________________________________________________
activation_6 (Activation)    (None, 12, 12, 128)       0         
_________________________________________________________________
batch_normalization_6 (Batch (None, 12, 12, 128)       512       
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 6, 6, 128)         0         
_________________________________________________________________
dropout_3 (Dropout)          (None, 6, 6, 128)         0         
_________________________________________________________________
conv2d_7 (Conv2D)            (None, 6, 6, 256)         295168    
_________________________________________________________________
activation_7 (Activation)    (None, 6, 6, 256)         0         
_________________________________________________________________
batch_normalization_7 (Batch (None, 6, 6, 256)         1024      
_________________________________________________________________
conv2d_8 (Conv2D)            (None, 6, 6, 256)         590080    
_________________________________________________________________
activation_8 (Activation)    (None, 6, 6, 256)         0         
_________________________________________________________________
batch_normalization_8 (Batch (None, 6, 6, 256)         1024      
_________________________________________________________________
max_pooling2d_4 (MaxPooling2 (None, 3, 3, 256)         0         
_________________________________________________________________
dropout_4 (Dropout)          (None, 3, 3, 256)         0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 2304)              0         
_________________________________________________________________
dense_1 (Dense)              (None, 64)                147520    
_________________________________________________________________
activation_9 (Activation)    (None, 64)                0         
_________________________________________________________________
batch_normalization_9 (Batch (None, 64)                256       
_________________________________________________________________
dropout_5 (Dropout)          (None, 64)                0         
_________________________________________________________________
dense_2 (Dense)              (None, 64)                4160      
_________________________________________________________________
activation_10 (Activation)   (None, 64)                0         
_________________________________________________________________
batch_normalization_10 (Batc (None, 64)                256       
_________________________________________________________________
dropout_6 (Dropout)          (None, 64)                0         
_________________________________________________________________
dense_3 (Dense)              (None, 7)                 455       
_________________________________________________________________
activation_11 (Activation)   (None, 7)                 0         
=================================================================
Total params: 1,328,167
Trainable params: 1,325,991
Non-trainable params: 2,176
_________________________________________________________________
None
Epoch 1/25
215/897 [======>.......................] - ETA: 1:35:14 - loss: 2.6460 - accuracy: 0.1669/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py:616: UserWarning: The input 416 could not be retrieved. It could be because a worker has died.
  UserWarning)
349/897 [==========>...................] - ETA: 1:23:21 - loss: 2.4862 - accuracy: 0.1751/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py:616: UserWarning: The input 834 could not be retrieved. It could be because a worker has died.
  UserWarning)
371/897 [===========>..................] - ETA: 1:21:24 - loss: 2.4653 - accuracy: 0.1763/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py:616: UserWarning: The input 278 could not be retrieved. It could be because a worker has died.
  UserWarning)
404/897 [============>.................] - ETA: 1:17:04 - loss: 2.4330 - accuracy: 0.1795/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py:616: UserWarning: The input 790 could not be retrieved. It could be because a worker has died.
  UserWarning)
582/897 [==================>...........] - ETA: 47:53 - loss: 2.3011 - accuracy: 0.1857/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py:616: UserWarning: The input 540 could not be retrieved. It could be because a worker has died.
  UserWarning)
589/897 [==================>...........] - ETA: 47:17 - loss: 2.2974 - accuracy: 0.1862/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py:616: UserWarning: The input 683 could not be retrieved. It could be because a worker has died.
  UserWarning)
598/897 [===================>..........] - ETA: 46:18 - loss: 2.2922 - accuracy: 0.1867/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py:616: UserWarning: The input 377 could not be retrieved. It could be because a worker has died.
  UserWarning)
599/897 [===================>..........] - ETA: 46:32 - loss: 2.2915 - accuracy: 0.1868/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py:616: UserWarning: The input 553 could not be retrieved. It could be because a worker has died.
  UserWarning)
897/897 [==============================] - 9128s 10s/step - loss: 2.1646 - accuracy: 0.1957 - val_loss: 1.7494 - val_accuracy: 0.2464

Epoch 00001: val_loss improved from inf to 1.74936, saving model to /content/gdrive/My Drive/FACE_EMOTION/Emotion.h5
Epoch 2/25
897/897 [==============================] - 793s 884ms/step - loss: 1.8200 - accuracy: 0.2411 - val_loss: 1.6999 - val_accuracy: 0.2679

Epoch 00002: val_loss improved from 1.74936 to 1.69991, saving model to /content/gdrive/My Drive/FACE_EMOTION/Emotion.h5
Epoch 3/25
897/897 [==============================] - 786s 876ms/step - loss: 1.7905 - accuracy: 0.2552 - val_loss: 1.6541 - val_accuracy: 0.2769

Epoch 00003: val_loss improved from 1.69991 to 1.65408, saving model to /content/gdrive/My Drive/FACE_EMOTION/Emotion.h5
Epoch 4/25
897/897 [==============================] - 792s 883ms/step - loss: 1.7651 - accuracy: 0.2678 - val_loss: 1.7076 - val_accuracy: 0.3112

Epoch 00004: val_loss did not improve from 1.65408
Epoch 5/25
897/897 [==============================] - 797s 888ms/step - loss: 1.7008 - accuracy: 0.3080 - val_loss: 1.6563 - val_accuracy: 0.3916

Epoch 00005: val_loss did not improve from 1.65408
Epoch 6/25
897/897 [==============================] - 802s 894ms/step - loss: 1.6077 - accuracy: 0.3679 - val_loss: 1.4672 - val_accuracy: 0.4667

Epoch 00006: val_loss improved from 1.65408 to 1.46716, saving model to /content/gdrive/My Drive/FACE_EMOTION/Emotion.h5
Epoch 7/25
897/897 [==============================] - 797s 888ms/step - loss: 1.5350 - accuracy: 0.4026 - val_loss: 1.3367 - val_accuracy: 0.5046

Epoch 00007: val_loss improved from 1.46716 to 1.33671, saving model to /content/gdrive/My Drive/FACE_EMOTION/Emotion.h5
Epoch 8/25
897/897 [==============================] - 798s 889ms/step - loss: 1.4896 - accuracy: 0.4260 - val_loss: 1.4756 - val_accuracy: 0.5007

Epoch 00008: val_loss did not improve from 1.33671
Epoch 9/25
897/897 [==============================] - 792s 882ms/step - loss: 1.4532 - accuracy: 0.4421 - val_loss: 1.0994 - val_accuracy: 0.5353

Epoch 00009: val_loss improved from 1.33671 to 1.09944, saving model to /content/gdrive/My Drive/FACE_EMOTION/Emotion.h5
Epoch 10/25
897/897 [==============================] - 783s 873ms/step - loss: 1.4180 - accuracy: 0.4572 - val_loss: 1.4268 - val_accuracy: 0.5409

Epoch 00010: val_loss did not improve from 1.09944
Epoch 11/25
897/897 [==============================] - 793s 884ms/step - loss: 1.4026 - accuracy: 0.4655 - val_loss: 1.3603 - val_accuracy: 0.5164

Epoch 00011: val_loss did not improve from 1.09944
Epoch 12/25
897/897 [==============================] - 788s 879ms/step - loss: 1.3859 - accuracy: 0.4739 - val_loss: 1.0110 - val_accuracy: 0.5597

Epoch 00012: val_loss improved from 1.09944 to 1.01103, saving model to /content/gdrive/My Drive/FACE_EMOTION/Emotion.h5
Epoch 13/25
897/897 [==============================] - 795s 886ms/step - loss: 1.3705 - accuracy: 0.4785 - val_loss: 1.1454 - val_accuracy: 0.5572

Epoch 00013: val_loss did not improve from 1.01103
Epoch 14/25
897/897 [==============================] - 791s 881ms/step - loss: 1.3620 - accuracy: 0.4833 - val_loss: 1.1537 - val_accuracy: 0.5626

Epoch 00014: val_loss did not improve from 1.01103
Epoch 15/25
897/897 [==============================] - 784s 874ms/step - loss: 1.3404 - accuracy: 0.4918 - val_loss: 1.0923 - val_accuracy: 0.5581

Epoch 00015: val_loss did not improve from 1.01103

Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.
Epoch 16/25
897/897 [==============================] - 786s 876ms/step - loss: 1.3124 - accuracy: 0.5053 - val_loss: 0.7192 - val_accuracy: 0.5884

Epoch 00016: val_loss improved from 1.01103 to 0.71925, saving model to /content/gdrive/My Drive/FACE_EMOTION/Emotion.h5
Epoch 17/25
897/897 [==============================] - 786s 876ms/step - loss: 1.2891 - accuracy: 0.5155 - val_loss: 1.0852 - val_accuracy: 0.5777

Epoch 00017: val_loss did not improve from 0.71925
Epoch 18/25
897/897 [==============================] - 799s 891ms/step - loss: 1.2797 - accuracy: 0.5203 - val_loss: 1.1574 - val_accuracy: 0.5932

Epoch 00018: val_loss did not improve from 0.71925
Epoch 19/25
897/897 [==============================] - 784s 874ms/step - loss: 1.2803 - accuracy: 0.5180 - val_loss: 0.8795 - val_accuracy: 0.6073

Epoch 00019: val_loss did not improve from 0.71925

Epoch 00019: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.
Epoch 20/25
897/897 [==============================] - 803s 896ms/step - loss: 1.2692 - accuracy: 0.5234 - val_loss: 0.8892 - val_accuracy: 0.5985

Epoch 00020: val_loss did not improve from 0.71925
Epoch 21/25
897/897 [==============================] - 783s 873ms/step - loss: 1.2639 - accuracy: 0.5237 - val_loss: 0.8332 - val_accuracy: 0.6039

Epoch 00021: val_loss did not improve from 0.71925
Epoch 22/25
897/897 [==============================] - 780s 870ms/step - loss: 1.2670 - accuracy: 0.5273 - val_loss: 1.0826 - val_accuracy: 0.6002

Epoch 00022: val_loss did not improve from 0.71925

Epoch 00022: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.
Epoch 23/25
897/897 [==============================] - 788s 878ms/step - loss: 1.2603 - accuracy: 0.5271 - val_loss: 0.8388 - val_accuracy: 0.5974

Epoch 00023: val_loss did not improve from 0.71925
Epoch 24/25
897/897 [==============================] - 784s 874ms/step - loss: 1.2530 - accuracy: 0.5297 - val_loss: 1.2485 - val_accuracy: 0.6137

Epoch 00024: val_loss did not improve from 0.71925
Epoch 25/25
897/897 [==============================] - 793s 884ms/step - loss: 1.2565 - accuracy: 0.5298 - val_loss: 1.0570 - val_accuracy: 0.6008
Restoring model weights from the end of the best epoch

Epoch 00025: val_loss did not improve from 0.71925

Epoch 00025: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.
Epoch 00025: early stopping